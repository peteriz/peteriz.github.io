<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Peter Izsak</title><link>/</link><description>Recent content on Peter Izsak</description><generator>Hugo -- gohugo.io</generator><language>en</language><lastBuildDate>Mon, 11 Mar 2019 00:00:00 +0000</lastBuildDate><atom:link href="/index.xml" rel="self" type="application/rss+xml"/><item><title>Publications</title><link>/publications/</link><pubDate>Mon, 11 Mar 2019 00:00:00 +0000</pubDate><guid>/publications/</guid><description>2024 Link to heading HELMET: How to Evaluate Long-Context Language Models Effectively and Thoroughly Howard Yen, Tianyu Gao, Minmin Hou, Ke Ding, Daniel Fleischer, Peter Izsak, Moshe Wasserblat, Danqi Chen Preprint Paper | Repo
RAG Foundry: A Framework for Enhancing LLMs for Retrieval Augmented Generation Daniel Fleischer, Moshe Berchansky, Moshe Wasserblat and Peter Izsak Preprint Paper | Repo
CoTAR: Chain-of-Thought Attribution Reasoning with Multi-level Granularity Moshe Berchansky, Daniel Fleischer, Moshe Wasserblat, Peter Izsak The 2024 Conference on Empirical Methods in Natural Language Processing (EMNLP 2024) Findings Paper</description></item><item><title/><link>/about/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/about/</guid><description>Hi, I am a Senior Data and Applied Scientist at Microsoft, where I explore, build, and apply my expertise in NLP to develop solutions for the healthcare industry. Previously, I was a Research Scientist and Team Lead at Intel Labs, where I delved into topics at the intersection of Deep Learning and NLP. I hold both an MSc and a BSc from the Technion.
I am deeply interested in the practical applications of large language models, particularly in terms of efficiency, hardware optimization, and their generative capabilities.</description></item><item><title/><link>/projects/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/projects/</guid><description>TBD</description></item></channel></rss>