<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Peter Izsak</title><link>/</link><description>Recent content on Peter Izsak</description><generator>Hugo</generator><language>en</language><lastBuildDate>Mon, 11 Mar 2019 00:00:00 +0000</lastBuildDate><atom:link href="/index.xml" rel="self" type="application/rss+xml"/><item><title>Publications</title><link>/publications/</link><pubDate>Mon, 11 Mar 2019 00:00:00 +0000</pubDate><guid>/publications/</guid><description>&lt;h4 id="2024">
 2024
 &lt;a class="heading-link" href="#2024">
 &lt;i class="fa fa-link" aria-hidden="true" title="Link to heading">&lt;/i>
 &lt;span class="sr-only">Link to heading&lt;/span>
 &lt;/a>
&lt;/h4>
&lt;p>&lt;strong>HELMET: How to Evaluate Long-Context Language Models Effectively and Thoroughly&lt;/strong> &lt;br>
&lt;em>Howard Yen, Tianyu Gao, Minmin Hou, Ke Ding, Daniel Fleischer, Peter Izsak, Moshe Wasserblat, Danqi Chen&lt;/em> &lt;br>
Preprint &lt;br>
&lt;a href="https://arxiv.org/abs/2410.02694">Paper&lt;/a> | &lt;a href="https://github.com/princeton-nlp/HELMET">Repo&lt;/a>&lt;/p>
&lt;p>&lt;strong>RAG Foundry: A Framework for Enhancing LLMs for Retrieval Augmented Generation&lt;/strong> &lt;br>
&lt;em>Daniel Fleischer, Moshe Berchansky, Moshe Wasserblat and Peter Izsak&lt;/em> &lt;br>
Preprint &lt;br>
&lt;a href="https://arxiv.org/abs/2408.02545">Paper&lt;/a> | &lt;a href="https://github.com/IntelLabs/RAGFoundry">Repo&lt;/a>&lt;/p>
&lt;p>&lt;strong>CoTAR: Chain-of-Thought Attribution Reasoning with Multi-level Granularity&lt;/strong> &lt;br>
&lt;em>Moshe Berchansky, Daniel Fleischer, Moshe Wasserblat, Peter Izsak&lt;/em> &lt;br>
The 2024 Conference on Empirical Methods in Natural Language Processing (EMNLP 2024) Findings &lt;br>
&lt;a href="https://arxiv.org/abs/2404.10513">Paper&lt;/a>&lt;/p></description></item><item><title/><link>/about/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/about/</guid><description>&lt;p>Hi, I am a Senior Data and Applied Scientist at Microsoft, where I explore, build, and apply my expertise in NLP to develop solutions for the healthcare industry. Previously, I was a Research Scientist and Team Lead at Intel Labs, where I delved into topics at the intersection of Deep Learning and NLP. I hold both an MSc and a BSc from the Technion.&lt;/p>
&lt;p>I am deeply interested in the practical applications of large language models, particularly in terms of efficiency, hardware optimization, and their generative capabilities. My focus is on leveraging these powerful tools to make a meaningful impact on humanity.&lt;/p></description></item><item><title/><link>/projects/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/projects/</guid><description>&lt;p>TBD&lt;/p></description></item></channel></rss>